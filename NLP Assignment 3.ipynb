{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "305c9c76-108b-4aac-9d5d-b63a504cc09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Explain the basic architecture of RNN cell.\n",
    "# 2. Explain Backpropagation through time (BPTT)\n",
    "# 3. Explain Vanishing and exploding gradients\n",
    "# 4. Explain Long short-term memory (LSTM)\n",
    "# 5. Explain Gated recurrent unit (GRU)\n",
    "# 6. Explain Peephole LSTM\n",
    "# 7. Bidirectional RNNs\n",
    "# 8. Explain the gates of LSTM with equations.\n",
    "# 9. Explain BiLSTM\n",
    "# 10. Explain BiGRU\n",
    "\n",
    "\n",
    "# Ans:\n",
    "# 1. The basic architecture of an RNN cell consists of an input, a hidden state, and an output. The input and the previous hidden state \n",
    "# are combined and passed through an activation function to calculate the current hidden state. The hidden state is then used to generate \n",
    "# the output.\n",
    "\n",
    "# 2. Backpropagation through time (BPTT) is a training algorithm for RNNs. It applies the backpropagation algorithm, which computes \n",
    "# the gradients of the loss function with respect to the weights, to the unfolded computational graph of the RNN over a sequence of \n",
    "# time steps.\n",
    "\n",
    "# 3. Vanishing gradients refer to the issue when the gradients in the backpropagation process diminish exponentially, making it difficult\n",
    "# for the RNN to learn long-term dependencies. Exploding gradients, on the other hand, occur when the gradients grow exponentially,\n",
    "# leading to unstable training.\n",
    "\n",
    "# 4. Long short-term memory (LSTM) is an RNN architecture designed to address the vanishing gradient problem and capture long-term \n",
    "# dependencies. It introduces memory cells and gates to selectively retain or forget information over time.\n",
    "\n",
    "# 5. Gated recurrent unit (GRU) is another type of RNN architecture that also addresses the vanishing gradient problem and captures\n",
    "# long-term dependencies. It simplifies the LSTM by combining the forget and input gates into a single update gate.\n",
    "\n",
    "# 6. Peephole LSTM is an extension of the LSTM architecture that introduces connections between the cell state and the gates. \n",
    "# This allows the gates to directly observe the cell state, enabling more precise control over the information flow.\n",
    "\n",
    "# 7. Bidirectional RNNs process input sequences in both forward and backward directions, combining the information from past and future\n",
    "# context. This allows the model to capture dependencies from both directions, enhancing the understanding of the input sequence.\n",
    "\n",
    "# 8. The gates of an LSTM include the input gate (i), the forget gate (f), and the output gate (o). These gates control the flow of \n",
    "# information in the LSTM. The equations for the gates are:\n",
    "\n",
    "# Input gate: i(t) = sigmoid(W_i * [h(t-1), x(t)] + b_i)\n",
    "# Forget gate: f(t) = sigmoid(W_f * [h(t-1), x(t)] + b_f)\n",
    "# Output gate: o(t) = sigmoid(W_o * [h(t-1), x(t)] + b_o)\n",
    "# BiLSTM (Bidirectional LSTM) is an extension of LSTM that incorporates bidirectional processing. It consists of two LSTM layers, \n",
    "# one processing the input sequence in the forward direction and the other in the backward direction. The outputs from both directions \n",
    "# are combined to capture information from both past and future context.\n",
    "\n",
    "# 9. BiGRU (Bidirectional GRU) is similar to BiLSTM but uses GRU units instead of LSTM units. It combines the forward and backward \n",
    "# processing of GRU layers to capture information from both directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdcbead-18f3-427a-a153-56209b9888a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
